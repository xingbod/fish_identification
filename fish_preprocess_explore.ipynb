{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites \n",
    "\n",
    "### A. In addition to opencv and numpy, you need the following python packages :\n",
    "1. **imgaug** : https://github.com/aleju/imgaug \n",
    "> Helps with image augmentation\n",
    "2. **shapely** : https://github.com/Toblerity/Shapely\n",
    "> For the manipulation and analysis of geometric objects in the Cartesian plane. It is useful here when we want to check if the bounding box of a card corner is covered by another card\n",
    "3. **tqdm** : https://github.com/tqdm/tqdm\n",
    "> A progress bar tool. Not mandatory but convenient when you generate thousands of images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "from glob import glob \n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from shapely.geometry import Polygon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some convenient functions used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_img(img,polygons=[],channels=\"bgr\",size=9):\n",
    "    \"\"\"\n",
    "        Function to display an inline image, and draw optional polygons (bounding boxes, convex hulls) on it.\n",
    "        Use the param 'channels' to specify the order of the channels (\"bgr\" for an image coming from OpenCV world)\n",
    "    \"\"\"\n",
    "    if not isinstance(polygons,list):\n",
    "        polygons=[polygons]    \n",
    "    if channels==\"bgr\": # bgr (cv2 image)\n",
    "        nb_channels=img.shape[2]\n",
    "        if nb_channels==4:\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)    \n",
    "    fig,ax=plt.subplots(figsize=(size,size))\n",
    "    ax.set_facecolor((0,0,0))\n",
    "    ax.imshow(img)\n",
    "    for polygon in polygons:\n",
    "        # An polygon has either shape (n,2), \n",
    "        # either (n,1,2) if it is a cv2 contour (like convex hull).\n",
    "        # In the latter case, reshape in (n,2)\n",
    "        if len(polygon.shape)==3:\n",
    "            polygon=polygon.reshape(-1,2)\n",
    "        patch=patches.Polygon(polygon,linewidth=1,edgecolor='g',facecolor='none')\n",
    "        ax.add_patch(patch)\n",
    "\n",
    "def give_me_filename(dirname, suffixes, prefix=\"\"):\n",
    "    \"\"\"\n",
    "        Function that returns a filename or a list of filenames in directory 'dirname'\n",
    "        that does not exist yet. If 'suffixes' is a list, one filename per suffix in 'suffixes':\n",
    "        filename = dirname + \"/\" + prefix + random number + \".\" + suffix\n",
    "        Same random number for all the file name\n",
    "        Ex: \n",
    "        > give_me_filename(\"dir\",\"jpg\", prefix=\"prefix\")\n",
    "        'dir/prefix408290659.jpg'\n",
    "        > give_me_filename(\"dir\",[\"jpg\",\"xml\"])\n",
    "        ['dir/877739594.jpg', 'dir/877739594.xml']        \n",
    "    \"\"\"\n",
    "    if not isinstance(suffixes, list):\n",
    "        suffixes=[suffixes]\n",
    "    \n",
    "    suffixes=[p if p[0]=='.' else '.'+p for p in suffixes]\n",
    "          \n",
    "    while True:\n",
    "        bname=\"%09d\"%random.randint(0,999999999)\n",
    "        fnames=[]\n",
    "        for suffix in suffixes:\n",
    "            fname=os.path.join(dirname,prefix+bname+suffix)\n",
    "            if not os.path.isfile(fname):\n",
    "                fnames.append(fname)\n",
    "                \n",
    "        if len(fnames) == len(suffixes): break\n",
    "    \n",
    "    if len(fnames)==1:\n",
    "        return fnames[0]\n",
    "    else:\n",
    "        return fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findHull(img, debug=\"no\"):\n",
    "    \"\"\"\n",
    "        Find in the zone 'corner' of image 'img' and return, the convex hull delimiting\n",
    "        the value and suit symbols\n",
    "        'corner' (shape (4,2)) is an array of 4 points delimiting a rectangular zone, \n",
    "        takes one of the 2 possible values : refCornerHL or refCornerLR\n",
    "        debug=\n",
    "    \"\"\"\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    corner=corner.astype(np.int)\n",
    "\n",
    "    # We will focus on the zone of 'img' delimited by 'corner'\n",
    "    x1=int(corner[0][0])\n",
    "    y1=int(corner[0][1])\n",
    "    x2=int(corner[2][0])\n",
    "    y2=int(corner[2][1])\n",
    "    w=x2-x1\n",
    "    h=y2-y1\n",
    "    zone=img[y1:y2,x1:x2].copy()\n",
    "\n",
    "    strange_cnt=np.zeros_like(zone)\n",
    "    gray=cv2.cvtColor(zone,cv2.COLOR_BGR2GRAY)\n",
    "    thld=cv2.Canny(gray,30,200)\n",
    "    thld = cv2.dilate(thld,kernel,iterations=1)\n",
    "    if debug!=\"no\": cv2.imshow(\"thld\",thld)\n",
    "    \n",
    "    # Find the contours\n",
    "    _,contours,_=cv2.findContours(thld.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    min_area=30 # We will reject contours with small area. TWEAK, 'zoom' dependant\n",
    "    min_solidity=0.3 # Reject contours with a low solidity. TWEAK\n",
    "    \n",
    "    concat_contour=None # We will aggregate in 'concat_contour' the contours that we want to keep\n",
    "    \n",
    "    ok=True\n",
    "    for c in contours:\n",
    "        area=cv2.contourArea(c)\n",
    "\n",
    "        hull = cv2.convexHull(c)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = float(area)/hull_area\n",
    "        # Determine the center of gravity (cx,cy) of the contour\n",
    "        M=cv2.moments(c)\n",
    "        cx=int(M['m10']/M['m00'])\n",
    "        cy=int(M['m01']/M['m00'])\n",
    "        #  abs(w/2-cx)<w*0.3 and abs(h/2-cy)<h*0.4 : TWEAK, the idea here is to keep only the contours which are closed to the center of the zone\n",
    "        if area >= min_area and abs(w/2-cx)<w*0.3 and abs(h/2-cy)<h*0.4 and solidity>min_solidity:\n",
    "            if debug != \"no\" :\n",
    "                cv2.drawContours(zone,[c],0,(255,0,0),-1)\n",
    "            if concat_contour is None:\n",
    "                concat_contour=c\n",
    "            else:\n",
    "                concat_contour=np.concatenate((concat_contour,c))\n",
    "        if debug != \"no\" and solidity <= min_solidity :\n",
    "            print(\"Solidity\",solidity)\n",
    "            cv2.drawContours(strange_cnt,[c],0,255,2)\n",
    "            cv2.imshow(\"Strange contours\",strange_cnt)\n",
    "            \n",
    "     \n",
    "    if concat_contour is not None:\n",
    "        # At this point, we suppose that 'concat_contour' contains only the contours corresponding the value and suit symbols   \n",
    "        # We can now determine the hull\n",
    "        hull=cv2.convexHull(concat_contour)\n",
    "        hull_area=cv2.contourArea(hull)\n",
    "        # If the area of the hull is to small or too big, there may be a problem\n",
    "        min_hull_area=940 # TWEAK, deck and 'zoom' dependant\n",
    "        max_hull_area=2120 # TWEAK, deck and 'zoom' dependant\n",
    "        if hull_area < min_hull_area or hull_area > max_hull_area: \n",
    "            ok=False\n",
    "            if debug!=\"no\":\n",
    "                print(\"Hull area=\",hull_area,\"too large or too small\")\n",
    "        # So far, the coordinates of the hull are relative to 'zone'\n",
    "        # We need the coordinates relative to the image -> 'hull_in_img' \n",
    "        hull_in_img=hull+corner[0]\n",
    "\n",
    "    else:\n",
    "        ok=False\n",
    "    \n",
    "    \n",
    "    if debug != \"no\" :\n",
    "        if concat_contour is not None:\n",
    "            cv2.drawContours(zone,[hull],0,(0,255,0),1)\n",
    "            cv2.drawContours(img,[hull_in_img],0,(0,255,0),1)\n",
    "        cv2.imshow(\"Zone\",zone)\n",
    "        cv2.imshow(\"Image\",img)\n",
    "        if ok and debug!=\"pause_always\":\n",
    "            key=cv2.waitKey(1)\n",
    "        else:\n",
    "            key=cv2.waitKey(0)\n",
    "        if key==27:\n",
    "            return None\n",
    "    if ok == False:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    return hull_in_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'corner' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-76489b34c547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_UNCHANGED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhullHL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfindHull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mhullLR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfindHull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdisplay_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bd40e4c33c58>\u001b[0m in \u001b[0;36mfindHull\u001b[0;34m(img, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcorner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# We will focus on the zone of 'img' delimited by 'corner'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'corner' referenced before assignment"
     ]
    }
   ],
   "source": [
    "data_dir=\"/home/xingbo/Desktop/fish_identification/data/JPG/JPG/SESSION1/fish_2_255_1.jpg\" # Directory that will contain all kinds of data (the data we download and the data we generate)\n",
    "debug=True\n",
    "\n",
    "img=cv2.imread(data_dir,cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "hullHL=findHull(img,debug=debug)\n",
    "hullLR=findHull(img,debug=debug)\n",
    "display_img(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bord_size=2 # bord_size alpha=0\n",
    "alphamask=np.ones((cardH,cardW),dtype=np.uint8)*255\n",
    "cv2.rectangle(alphamask,(0,0),(cardW-1,cardH-1),0,bord_size)\n",
    "cv2.line(alphamask,(bord_size*3,0),(0,bord_size*3),0,bord_size)\n",
    "cv2.line(alphamask,(cardW-bord_size*3,0),(cardW,bord_size*3),0,bord_size)\n",
    "cv2.line(alphamask,(0,cardH-bord_size*3),(bord_size*3,cardH),0,bord_size)\n",
    "cv2.line(alphamask,(cardW-bord_size*3,cardH),(cardW,cardH-bord_size*3),0,bord_size)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(alphamask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function extract_card \n",
    "Extract from scene image (cv2/bgr) the part corresponding to the card and transforms it \n",
    "to fit into the reference card shape.\n",
    "We suppose here that the user facilitates as much as he can the extraction task by\n",
    "making the scene image simple (one card on uniform backgroung, not too blurry, correct lighting,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varianceOfLaplacian(img):\n",
    "    \"\"\"\n",
    "    Compute the Laplacian of the image and then return the focus\n",
    "    measure, which is simply the variance of the Laplacian\n",
    "    Source: A.Rosebrock, https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "    \"\"\"\n",
    "    return cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "\n",
    "def extract_card (img, output_fn=None, min_focus=120, debug=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    imgwarp=None\n",
    "    \n",
    "    # Check the image is not too blurry\n",
    "    focus=varianceOfLaplacian(img)\n",
    "    if focus < min_focus: \n",
    "        if debug: print(\"Focus too low :\", focus)\n",
    "        return False,None\n",
    "    \n",
    "    # Convert in gray color\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Noise-reducing and edge-preserving filter\n",
    "    gray=cv2.bilateralFilter(gray,11,17,17)\n",
    "    \n",
    "    # Edge extraction\n",
    "    edge=cv2.Canny(gray,30,200)\n",
    "    \n",
    "    # Find the contours in the edged image\n",
    "    _,cnts, _ = cv2.findContours(edge.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # We suppose that the contour with largest area corresponds to the contour delimiting the card\n",
    "    cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "    \n",
    "    # We want to check that 'cnt' is the contour of a rectangular shape\n",
    "    # First, determine 'box', the minimum area bounding rectangle of 'cnt'\n",
    "    # Then compare area of 'cnt' and area of 'box'\n",
    "    # Both areas sould be very close\n",
    "    rect=cv2.minAreaRect(cnt)\n",
    "    box=cv2.boxPoints(rect)\n",
    "    box=np.int0(box)\n",
    "    areaCnt=cv2.contourArea(cnt)\n",
    "    areaBox=cv2.contourArea(box)\n",
    "    valid=areaCnt/areaBox>0.95\n",
    "    \n",
    "    if valid:\n",
    "        # We want transform the zone inside the contour into the reference rectangle of dimensions (cardW,cardH)\n",
    "        ((xr,yr),(wr,hr),thetar)=rect\n",
    "        # Determine 'Mp' the transformation that transforms 'box' into the reference rectangle\n",
    "        if wr>hr:\n",
    "            Mp=cv2.getPerspectiveTransform(np.float32(box),refCard)\n",
    "        else:\n",
    "            Mp=cv2.getPerspectiveTransform(np.float32(box),refCardRot)\n",
    "        # Determine the warped image by applying the transformation to the image\n",
    "        imgwarp=cv2.warpPerspective(img,Mp,(cardW,cardH))\n",
    "        # Add alpha layer\n",
    "        imgwarp=cv2.cvtColor(imgwarp,cv2.COLOR_BGR2BGRA)\n",
    "        \n",
    "        # Shape of 'cnt' is (n,1,2), type=int with n = number of points\n",
    "        # We reshape into (1,n,2), type=float32, before feeding to perspectiveTransform\n",
    "        cnta=cnt.reshape(1,-1,2).astype(np.float32)\n",
    "        # Apply the transformation 'Mp' to the contour\n",
    "        cntwarp=cv2.perspectiveTransform(cnta,Mp)\n",
    "        cntwarp=cntwarp.astype(np.int)\n",
    "        \n",
    "        # We build the alpha channel so that we have transparency on the\n",
    "        # external border of the card\n",
    "        # First, initialize alpha channel fully transparent\n",
    "        alphachannel=np.zeros(imgwarp.shape[:2],dtype=np.uint8)\n",
    "        # Then fill in the contour to make opaque this zone of the card \n",
    "        cv2.drawContours(alphachannel,cntwarp,0,255,-1)\n",
    "        \n",
    "        # Apply the alphamask onto the alpha channel to clean it\n",
    "        alphachannel=cv2.bitwise_and(alphachannel,alphamask)\n",
    "        \n",
    "        # Add the alphachannel to the warped image\n",
    "        imgwarp[:,:,3]=alphachannel\n",
    "        \n",
    "        # Save the image to file\n",
    "        if output_fn is not None:\n",
    "            cv2.imwrite(output_fn,imgwarp)\n",
    "        \n",
    "    if debug:\n",
    "        cv2.imshow(\"Gray\",gray)\n",
    "        cv2.imshow(\"Canny\",edge)\n",
    "        edge_bgr=cv2.cvtColor(edge,cv2.COLOR_GRAY2BGR)\n",
    "        cv2.drawContours(edge_bgr,[box],0,(0,0,255),3)\n",
    "        cv2.drawContours(edge_bgr,[cnt],0,(0,255,0),-1)\n",
    "        cv2.imshow(\"Contour with biggest area\",edge_bgr)\n",
    "        if valid:\n",
    "            cv2.imshow(\"Alphachannel\",alphachannel)\n",
    "            cv2.imshow(\"Extracted card\",imgwarp)\n",
    "\n",
    "    return valid,imgwarp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on one image\n",
    "debug=False\n",
    "img=cv2.imread(\"test/scene.png\")\n",
    "display_img(img)\n",
    "valid,card=extract_card(img,\"test/extracted_card.png\", debug=debug)\n",
    "if valid:\n",
    "    display_img(card)\n",
    "if debug:\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function extract_cards_from_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cards_from_video(video_fn, output_dir=None, keep_ratio=5, min_focus=120, debug=False):\n",
    "    \"\"\"\n",
    "        Extract cards from media file 'video_fn' \n",
    "        If 'output_dir' is specified, the cards are saved in 'output_dir'.\n",
    "        One file per card with a random file name\n",
    "        Because 2 consecutives frames are probably very similar, we don't use every frame of the video, \n",
    "        but only one every 'keep_ratio' frames\n",
    "        \n",
    "        Returns list of extracted images\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(video_fn):\n",
    "        print(f\"Video file {video_fn} does not exist !!!\")\n",
    "        return -1,[]\n",
    "    if output_dir is not None and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    cap=cv2.VideoCapture(video_fn)\n",
    "    \n",
    "    frame_nb=0\n",
    "    imgs_list=[]\n",
    "    while True:\n",
    "        ret,img=cap.read()\n",
    "        if not ret: break\n",
    "        # Work on every 'keep_ratio' frames\n",
    "        if frame_nb%keep_ratio==0:\n",
    "            if output_dir is not None:\n",
    "                output_fn=give_me_filename(output_dir,\"png\")\n",
    "            else:\n",
    "                output_fn=None\n",
    "            valid,card_img = extract_card(img,output_fn,min_focus=min_focus,debug=debug)\n",
    "            if debug: \n",
    "                k=cv2.waitKey(1)\n",
    "                if k==27: break\n",
    "            if valid:\n",
    "                imgs_list.append(card_img)\n",
    "        frame_nb+=1\n",
    "    \n",
    "    if debug:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return imgs_list\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test card extraction from a video   \n",
    "imgs=extract_cards_from_video(\"test/2c.avi\",output_dir=\"test/2c\",debug=True)\n",
    "print(\"Nb images extracted:\",len(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Card extraction from all the videos\n",
    "We suppose we have for each card_name (ex: 2d, Kc, Ah) one video file named 'card_name.extension' (ex: 2d.avi, Kc.avi, Ah.avi) in a common directory (ex: data/video). If you use images instead of movies, the script below should work by setting the variable 'extension' below to \"jpg\" or \"png\". \n",
    "The cards from a video, or the card from an image, will be extracted in a subdirectory named 'card_name' placed in the directory 'imgs_dir' (ex: data/cards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir=\"data/video\"\n",
    "extension=\"avi\"\n",
    "imgs_dir=\"data/cards\"\n",
    "\n",
    "for suit in card_suits:\n",
    "    for value in card_values:\n",
    "        \n",
    "        card_name=value+suit\n",
    "        video_fn=os.path.join(video_dir,card_name+\".\"+extension)\n",
    "        output_dir=os.path.join(imgs_dir,card_name)\n",
    "        if not os.path.isdir(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        imgs=extract_cards_from_video(video_fn,output_dir)\n",
    "        print(\"Extracted images for %s : %d\"%(card_name,len(imgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before going on, check that everything looks good\n",
    "We randomly choose and display one of the extracted card. We also draw on the card the 2 polygons defined by refCornerHL and refCornerLR. Check that the value and suit symbols are well inside the polygons. If not, check the hand-made measures : cardW, cardH, cornerXmin, cornerXmax, cornerYmin and cornerYmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a few times...\n",
    "imgs_dir=\"data/cards\"\n",
    "imgs_fns=glob(imgs_dir+\"/*/*.png\")\n",
    "img_fn=random.choice(imgs_fns)\n",
    "display_img(cv2.imread(img_fn,cv2.IMREAD_UNCHANGED),polygons=[refCornerHL,refCornerLR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the convex hulls\n",
    "<img src=\"img/convex_hull.jpg\" alt=\"Convex hull\" title=\"Convex hull\" />\n",
    "This function 'find_hull' finds the convex hull in one of the corner of a card image.\n",
    "The convex hull is the minimal convex polygon that contains both the value and the suit symbols. \n",
    "\n",
    "When I wrote this function it needed a lot of tweaking to make it work. It works well with my deck of cards, but I can't guarantee it is adapted to other decks. Search for the keyword TWEAK in the comments to find the variable and values that may need some tweak. Some of them depend on the value of global variable 'zoom'.\n",
    "It may happen that the function can't find a valid convex hull for a card. It is not a problem, it only means that this card won't be used to generate the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findHull(img, corner=refCornerHL, debug=\"no\"):\n",
    "    \"\"\"\n",
    "        Find in the zone 'corner' of image 'img' and return, the convex hull delimiting\n",
    "        the value and suit symbols\n",
    "        'corner' (shape (4,2)) is an array of 4 points delimiting a rectangular zone, \n",
    "        takes one of the 2 possible values : refCornerHL or refCornerLR\n",
    "        debug=\n",
    "    \"\"\"\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    corner=corner.astype(np.int)\n",
    "\n",
    "    # We will focus on the zone of 'img' delimited by 'corner'\n",
    "    x1=int(corner[0][0])\n",
    "    y1=int(corner[0][1])\n",
    "    x2=int(corner[2][0])\n",
    "    y2=int(corner[2][1])\n",
    "    w=x2-x1\n",
    "    h=y2-y1\n",
    "    zone=img[y1:y2,x1:x2].copy()\n",
    "\n",
    "    strange_cnt=np.zeros_like(zone)\n",
    "    gray=cv2.cvtColor(zone,cv2.COLOR_BGR2GRAY)\n",
    "    thld=cv2.Canny(gray,30,200)\n",
    "    thld = cv2.dilate(thld,kernel,iterations=1)\n",
    "    if debug!=\"no\": cv2.imshow(\"thld\",thld)\n",
    "    \n",
    "    # Find the contours\n",
    "    _,contours,_=cv2.findContours(thld.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    min_area=30 # We will reject contours with small area. TWEAK, 'zoom' dependant\n",
    "    min_solidity=0.3 # Reject contours with a low solidity. TWEAK\n",
    "    \n",
    "    concat_contour=None # We will aggregate in 'concat_contour' the contours that we want to keep\n",
    "    \n",
    "    ok=True\n",
    "    for c in contours:\n",
    "        area=cv2.contourArea(c)\n",
    "\n",
    "        hull = cv2.convexHull(c)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = float(area)/hull_area\n",
    "        # Determine the center of gravity (cx,cy) of the contour\n",
    "        M=cv2.moments(c)\n",
    "        cx=int(M['m10']/M['m00'])\n",
    "        cy=int(M['m01']/M['m00'])\n",
    "        #  abs(w/2-cx)<w*0.3 and abs(h/2-cy)<h*0.4 : TWEAK, the idea here is to keep only the contours which are closed to the center of the zone\n",
    "        if area >= min_area and abs(w/2-cx)<w*0.3 and abs(h/2-cy)<h*0.4 and solidity>min_solidity:\n",
    "            if debug != \"no\" :\n",
    "                cv2.drawContours(zone,[c],0,(255,0,0),-1)\n",
    "            if concat_contour is None:\n",
    "                concat_contour=c\n",
    "            else:\n",
    "                concat_contour=np.concatenate((concat_contour,c))\n",
    "        if debug != \"no\" and solidity <= min_solidity :\n",
    "            print(\"Solidity\",solidity)\n",
    "            cv2.drawContours(strange_cnt,[c],0,255,2)\n",
    "            cv2.imshow(\"Strange contours\",strange_cnt)\n",
    "            \n",
    "     \n",
    "    if concat_contour is not None:\n",
    "        # At this point, we suppose that 'concat_contour' contains only the contours corresponding the value and suit symbols   \n",
    "        # We can now determine the hull\n",
    "        hull=cv2.convexHull(concat_contour)\n",
    "        hull_area=cv2.contourArea(hull)\n",
    "        # If the area of the hull is to small or too big, there may be a problem\n",
    "        min_hull_area=940 # TWEAK, deck and 'zoom' dependant\n",
    "        max_hull_area=2120 # TWEAK, deck and 'zoom' dependant\n",
    "        if hull_area < min_hull_area or hull_area > max_hull_area: \n",
    "            ok=False\n",
    "            if debug!=\"no\":\n",
    "                print(\"Hull area=\",hull_area,\"too large or too small\")\n",
    "        # So far, the coordinates of the hull are relative to 'zone'\n",
    "        # We need the coordinates relative to the image -> 'hull_in_img' \n",
    "        hull_in_img=hull+corner[0]\n",
    "\n",
    "    else:\n",
    "        ok=False\n",
    "    \n",
    "    \n",
    "    if debug != \"no\" :\n",
    "        if concat_contour is not None:\n",
    "            cv2.drawContours(zone,[hull],0,(0,255,0),1)\n",
    "            cv2.drawContours(img,[hull_in_img],0,(0,255,0),1)\n",
    "        cv2.imshow(\"Zone\",zone)\n",
    "        cv2.imshow(\"Image\",img)\n",
    "        if ok and debug!=\"pause_always\":\n",
    "            key=cv2.waitKey(1)\n",
    "        else:\n",
    "            key=cv2.waitKey(0)\n",
    "        if key==27:\n",
    "            return None\n",
    "    if ok == False:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    return hull_in_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test find_hull on a random card image\n",
    "# debug = \"no\" or \"pause_always\" or \"pause_on_pb\"\n",
    "# If debug!=\"no\", you may have to press a key to continue execution after pause\n",
    "debug=\"no\" \n",
    "imgs_dir=\"data/cards\"\n",
    "imgs_fns=glob(imgs_dir+\"/*/*.png\")\n",
    "img_fn=random.choice(imgs_fns)\n",
    "print(img_fn)\n",
    "img=cv2.imread(img_fn,cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "hullHL=findHull(img,refCornerHL,debug=debug)\n",
    "hullLR=findHull(img,refCornerLR,debug=debug)\n",
    "display_img(img,[refCornerHL,refCornerLR,hullHL,hullLR])\n",
    "\n",
    "if debug!=\"no\": cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all card image, calculate their convex hulls and save the whole in a pickle file (1x)\n",
    "\n",
    "The next times, we will directly load the pickle file \n",
    "The structure saved in the pickle file is a dictionnary named 'cards' of lists of triplets (img,hullHL,hullLR). The keys of the dictionnary are the card names (\"Ad\",\"10h\",... so 52 entries in the dictionnary). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir=\"data/cards\"\n",
    "\n",
    "cards={}\n",
    "for suit in card_suits:\n",
    "    for value in card_values:\n",
    "        card_name=value+suit        \n",
    "        card_dir=os.path.join(imgs_dir,card_name)\n",
    "        if not os.path.isdir(card_dir):\n",
    "            print(f\"!!! {card_dir} does not exist !!!\")\n",
    "            continue\n",
    "        cards[card_name]=[]\n",
    "        for f in glob(card_dir+\"/*.png\"):\n",
    "            img=cv2.imread(f,cv2.IMREAD_UNCHANGED)\n",
    "            hullHL=findHull(img,refCornerHL,debug=\"no\") \n",
    "            if hullHL is None: \n",
    "                print(f\"File {f} not used.\")\n",
    "                continue\n",
    "            hullLR=findHull(img,refCornerLR,debug=\"no\") \n",
    "            if hullLR is None: \n",
    "                print(f\"File {f} not used.\")\n",
    "                continue\n",
    "            # We store the image in \"rgb\" format (we don't need opencv anymore)\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGRA2RGBA)\n",
    "            cards[card_name].append((img,hullHL,hullLR))\n",
    "        print(f\"Nb images for {card_name} : {len(cards[card_name])}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Saved in :\",cards_pck_fn)\n",
    "pickle.dump(cards,open(cards_pck_fn,'wb'))\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cards pickle file in 'cards'\n",
    "'cards' is an instance of the class Cards\n",
    "To get a random background image, call the method : cards.get_random() or cards.get_random(card_name) if you want a random card of a given value. Ex: cards.get_random('Ah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cards():\n",
    "    def __init__(self,cards_pck_fn=cards_pck_fn):\n",
    "        self._cards=pickle.load(open(cards_pck_fn,'rb'))\n",
    "        # self._cards is a dictionary where keys are card names (ex:'Kc') and values are lists of (img,hullHL,hullLR) \n",
    "        self._nb_cards_by_value={k:len(self._cards[k]) for k in self._cards}\n",
    "        print(\"Nb of cards loaded per name :\", self._nb_cards_by_value)\n",
    "        \n",
    "    def get_random(self, card_name=None, display=False):\n",
    "        if card_name is None:\n",
    "            card_name= random.choice(list(self._cards.keys()))\n",
    "        card,hull1,hull2=self._cards[card_name][random.randint(0,self._nb_cards_by_value[card_name]-1)]\n",
    "        if display:\n",
    "            if display: display_img(card,[hull1,hull2],\"rgb\")\n",
    "        return card,card_name,hull1,hull2\n",
    "    \n",
    "cards = Cards()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: display a random card\n",
    "_=cards.get_random(display=True)\n",
    "# Display a random Ace of spades\n",
    "#_=cards.get_random(\"As\",display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a scene\n",
    "We can now generate a scene (= image of the dataset). We are considering here only 2 kinds of scene (but nothing prevents you to add more scenarios):\n",
    "1. a scene with 2 cards: each card is randomly transformed (scaled, rotated, translated) independantly from the other;\n",
    "2. a scene with 3 cards : the 3 cards are grouped together (a bit randomly) to form a fan, then the group is randomly transformed.\n",
    "\n",
    "|   |   |\n",
    "|---|---|\n",
    "|<img src=\"img/gen_2_cards.jpg\" alt=\"Generated image with 2 cards\" title=\"Generated image with 2 cards\" />|<img src=\"img/gen_3_cards.jpg\" alt=\"Generated image with 3 cards\" title=\"Generated image with 3 cards\" />|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To save bounding boxes annotations in Pascal VOC format \n",
    "http://host.robots.ox.ac.uk/pascal/VOC/voc2008/htmldoc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_body_1=\"\"\"<annotation>\n",
    "        <folder>FOLDER</folder>\n",
    "        <filename>{FILENAME}</filename>\n",
    "        <path>{PATH}</path>\n",
    "        <source>\n",
    "                <database>Unknown</database>\n",
    "        </source>\n",
    "        <size>\n",
    "                <width>{WIDTH}</width>\n",
    "                <height>{HEIGHT}</height>\n",
    "                <depth>3</depth>\n",
    "        </size>\n",
    "\"\"\"\n",
    "xml_object=\"\"\" <object>\n",
    "                <name>{CLASS}</name>\n",
    "                <pose>Unspecified</pose>\n",
    "                <truncated>0</truncated>\n",
    "                <difficult>0</difficult>\n",
    "                <bndbox>\n",
    "                        <xmin>{XMIN}</xmin>\n",
    "                        <ymin>{YMIN}</ymin>\n",
    "                        <xmax>{XMAX}</xmax>\n",
    "                        <ymax>{YMAX}</ymax>\n",
    "                </bndbox>\n",
    "        </object>\n",
    "\"\"\"\n",
    "xml_body_2=\"\"\"</annotation>        \n",
    "\"\"\"\n",
    "\n",
    "def create_voc_xml(xml_file, img_file,listbba,display=False):\n",
    "    with open(xml_file,\"w\") as f:\n",
    "        f.write(xml_body_1.format(**{'FILENAME':os.path.basename(img_file), 'PATH':img_file,'WIDTH':imgW,'HEIGHT':imgH}))\n",
    "        for bba in listbba:            \n",
    "            f.write(xml_object.format(**{'CLASS':bba.classname,'XMIN':bba.x1,'YMIN':bba.y1,'XMAX':bba.x2,'YMAX':bba.y2}))\n",
    "        f.write(xml_body_2)\n",
    "        if display: print(\"New xml\",xml_file)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scenario with 2 cards:\n",
    "# The original image of a card has the shape (cardH,cardW,4)\n",
    "# We first paste it in a zero image of shape (imgH,imgW,4) at position decalX, decalY\n",
    "# so that the original image is centerd in the zero image\n",
    "decalX=int((imgW-cardW)/2)\n",
    "decalY=int((imgH-cardH)/2)\n",
    "\n",
    "# Scenario with 3 cards : decal values are different\n",
    "decalX3=int(imgW/2)\n",
    "decalY3=int(imgH/2-cardH)\n",
    "\n",
    "def kps_to_polygon(kps):\n",
    "    \"\"\"\n",
    "        Convert imgaug keypoints to shapely polygon\n",
    "    \"\"\"\n",
    "    pts=[(kp.x,kp.y) for kp in kps]\n",
    "    return Polygon(pts)\n",
    "\n",
    "def hull_to_kps(hull, decalX=decalX, decalY=decalY):\n",
    "    \"\"\"\n",
    "        Convert hull to imgaug keypoints\n",
    "    \"\"\"\n",
    "    # hull is a cv2.Contour, shape : Nx1x2\n",
    "    kps=[ia.Keypoint(x=p[0]+decalX,y=p[1]+decalY) for p in hull.reshape(-1,2)]\n",
    "    kps=ia.KeypointsOnImage(kps, shape=(imgH,imgW,3))\n",
    "    return kps\n",
    "\n",
    "def kps_to_BB(kps):\n",
    "    \"\"\"\n",
    "        Determine imgaug bounding box from imgaug keypoints\n",
    "    \"\"\"\n",
    "    extend=3 # To make the bounding box a little bit bigger\n",
    "    kpsx=[kp.x for kp in kps.keypoints]\n",
    "    minx=max(0,int(min(kpsx)-extend))\n",
    "    maxx=min(imgW,int(max(kpsx)+extend))\n",
    "    kpsy=[kp.y for kp in kps.keypoints]\n",
    "    miny=max(0,int(min(kpsy)-extend))\n",
    "    maxy=min(imgH,int(max(kpsy)+extend))\n",
    "    if minx==maxx or miny==maxy:\n",
    "        return None\n",
    "    else:\n",
    "        return ia.BoundingBox(x1=minx,y1=miny,x2=maxx,y2=maxy)\n",
    "\n",
    "\n",
    "# imgaug keypoints of the bounding box of a whole card\n",
    "cardKP = ia.KeypointsOnImage([\n",
    "    ia.Keypoint(x=decalX,y=decalY),\n",
    "    ia.Keypoint(x=decalX+cardW,y=decalY),   \n",
    "    ia.Keypoint(x=decalX+cardW,y=decalY+cardH),\n",
    "    ia.Keypoint(x=decalX,y=decalY+cardH)\n",
    "    ], shape=(imgH,imgW,3))\n",
    "\n",
    "# imgaug transformation for one card in scenario with 2 cards\n",
    "transform_1card = iaa.Sequential([\n",
    "    iaa.Affine(scale=[0.65,1]),\n",
    "    iaa.Affine(rotate=(-180,180)),\n",
    "    iaa.Affine(translate_percent={\"x\":(-0.25,0.25),\"y\":(-0.25,0.25)}),\n",
    "])\n",
    "\n",
    "# For the 3 cards scenario, we use 3 imgaug transforms, the first 2 are for individual cards, \n",
    "# and the third one for the group of 3 cards\n",
    "trans_rot1 = iaa.Sequential([\n",
    "    iaa.Affine(translate_px={\"x\": (10, 20)}),\n",
    "    iaa.Affine(rotate=(22,30))\n",
    "])\n",
    "trans_rot2 = iaa.Sequential([\n",
    "    iaa.Affine(translate_px={\"x\": (0, 5)}),\n",
    "    iaa.Affine(rotate=(10,15))\n",
    "])\n",
    "transform_3cards = iaa.Sequential([\n",
    "    iaa.Affine(translate_px={\"x\":decalX-decalX3,\"y\":decalY-decalY3}),\n",
    "    iaa.Affine(scale=[0.65,1]),\n",
    "    iaa.Affine(rotate=(-180,180)),\n",
    "    iaa.Affine(translate_percent={\"x\":(-0.2,0.2),\"y\":(-0.2,0.2)})   \n",
    "])\n",
    "\n",
    "# imgaug transformation for the background\n",
    "scaleBg=iaa.Scale({\"height\": imgH, \"width\": imgW})\n",
    "\n",
    "def augment(img, list_kps, seq, restart=True):\n",
    "    \"\"\"\n",
    "        Apply augmentation 'seq' to image 'img' and keypoints 'list_kps'\n",
    "        If restart is False, the augmentation has been made deterministic outside the function (used for 3 cards scenario)\n",
    "    \"\"\" \n",
    "    # Make sequence deterministic\n",
    "    while True:\n",
    "        if restart:\n",
    "            myseq=seq.to_deterministic()\n",
    "        else:\n",
    "            myseq=seq\n",
    "        # Augment image, keypoints and bbs \n",
    "        img_aug = myseq.augment_images([img])[0]\n",
    "        list_kps_aug = [myseq.augment_keypoints([kp])[0] for kp in list_kps]\n",
    "        list_bbs = [kps_to_BB(list_kps_aug[1]),kps_to_BB(list_kps_aug[2])]\n",
    "        valid=True\n",
    "        # Check the card bounding box stays inside the image\n",
    "        for bb in list_bbs:\n",
    "            if bb is None or int(round(bb.x2)) >= imgW or int(round(bb.y2)) >= imgH or int(bb.x1)<=0 or int(bb.y1)<=0:\n",
    "                valid=False\n",
    "                break\n",
    "        if valid: break\n",
    "        elif not restart:\n",
    "            img_aug=None\n",
    "            break\n",
    "                \n",
    "    return img_aug,list_kps_aug,list_bbs\n",
    "\n",
    "class BBA:  # Bounding box + annotations\n",
    "    def __init__(self,bb,classname):      \n",
    "        self.x1=int(round(bb.x1))\n",
    "        self.y1=int(round(bb.y1))\n",
    "        self.x2=int(round(bb.x2))\n",
    "        self.y2=int(round(bb.y2))\n",
    "        self.classname=classname\n",
    "\n",
    "class Scene:\n",
    "    def __init__(self,bg,img1, class1, hulla1,hullb1,img2, class2,hulla2,hullb2,img3=None, class3=None,hulla3=None,hullb3=None):\n",
    "        if img3 is not None:\n",
    "            self.create3CardsScene(bg,img1, class1, hulla1,hullb1,img2, class2,hulla2,hullb2,img3, class3,hulla3,hullb3)\n",
    "        else:\n",
    "            self.create2CardsScene(bg,img1, class1, hulla1,hullb1,img2, class2,hulla2,hullb2)\n",
    "\n",
    "    def create2CardsScene(self,bg,img1, class1, hulla1,hullb1,img2, class2,hulla2,hullb2):\n",
    "        kpsa1=hull_to_kps(hulla1)\n",
    "        kpsb1=hull_to_kps(hullb1)\n",
    "        kpsa2=hull_to_kps(hulla2)\n",
    "        kpsb2=hull_to_kps(hullb2)\n",
    "        \n",
    "        # Randomly transform 1st card\n",
    "        self.img1=np.zeros((imgH,imgW,4),dtype=np.uint8)\n",
    "        self.img1[decalY:decalY+cardH,decalX:decalX+cardW,:]=img1\n",
    "        self.img1,self.lkps1,self.bbs1=augment(self.img1,[cardKP,kpsa1,kpsb1],transform_1card)\n",
    "\n",
    "        # Randomly transform 2nd card. We want that card 2 does not partially cover a corner of 1 card.\n",
    "        # If so, we apply a new random transform to card 2\n",
    "        while True:\n",
    "            self.listbba=[]\n",
    "            self.img2=np.zeros((imgH,imgW,4),dtype=np.uint8)\n",
    "            self.img2[decalY:decalY+cardH,decalX:decalX+cardW,:]=img2\n",
    "            self.img2,self.lkps2,self.bbs2=augment(self.img2,[cardKP,kpsa2,kpsb2],transform_1card)\n",
    "\n",
    "            # mainPoly2: shapely polygon of card 2\n",
    "            mainPoly2=kps_to_polygon(self.lkps2[0].keypoints[0:4])\n",
    "            invalid=False\n",
    "            intersect_ratio=0.1\n",
    "            for i in range(1,3):\n",
    "                # smallPoly1: shapely polygon of one of the hull of card 1\n",
    "                smallPoly1=kps_to_polygon(self.lkps1[i].keypoints[:])\n",
    "                a=smallPoly1.area\n",
    "                # We calculate area of the intersection of card 1 corner with card 2\n",
    "                intersect=mainPoly2.intersection(smallPoly1)\n",
    "                ai=intersect.area\n",
    "                # If intersection area is small enough, we accept card 2\n",
    "                if (a-ai)/a > 1-intersect_ratio:\n",
    "                    self.listbba.append(BBA(self.bbs1[i-1],class1))\n",
    "                # If intersectio area is not small, but also not big enough, we want apply new transform to card 2\n",
    "                elif (a-ai)/a>intersect_ratio:\n",
    "                    invalid=True\n",
    "                    break\n",
    "                    \n",
    "            if not invalid: break\n",
    "            \n",
    "        self.class1=class1\n",
    "        self.class2=class2\n",
    "        for bb in self.bbs2:\n",
    "            self.listbba.append(BBA(bb,class2))\n",
    "        # Construct final image of the scene by superimposing: bg, img1 and img2\n",
    "        self.bg=scaleBg.augment_image(bg)\n",
    "        mask1=self.img1[:,:,3]\n",
    "        self.mask1=np.stack([mask1]*3,-1)\n",
    "        self.final=np.where(self.mask1,self.img1[:,:,0:3],self.bg)\n",
    "        mask2=self.img2[:,:,3]\n",
    "        self.mask2=np.stack([mask2]*3,-1)\n",
    "        self.final=np.where(self.mask2,self.img2[:,:,0:3],self.final)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def create3CardsScene(self,bg,img1, class1, hulla1,hullb1,img2, class2,hulla2,hullb2,img3, class3,hulla3,hullb3):\n",
    "        \n",
    "        kpsa1=hull_to_kps(hulla1,decalX3,decalY3)\n",
    "        kpsb1=hull_to_kps(hullb1,decalX3,decalY3)\n",
    "        kpsa2=hull_to_kps(hulla2,decalX3,decalY3)\n",
    "        kpsb2=hull_to_kps(hullb2,decalX3,decalY3)\n",
    "        kpsa3=hull_to_kps(hulla3,decalX3,decalY3)\n",
    "        kpsb3=hull_to_kps(hullb3,decalX3,decalY3)\n",
    "        self.img3=np.zeros((imgH,imgW,4),dtype=np.uint8)\n",
    "        self.img3[decalY3:decalY3+cardH,decalX3:decalX3+cardW,:]=img3\n",
    "        self.img3,self.lkps3,self.bbs3=augment(self.img3,[cardKP,kpsa3,kpsb3],trans_rot1)\n",
    "        self.img2=np.zeros((imgH,imgW,4),dtype=np.uint8)\n",
    "        self.img2[decalY3:decalY3+cardH,decalX3:decalX3+cardW,:]=img2\n",
    "        self.img2,self.lkps2,self.bbs2=augment(self.img2,[cardKP,kpsa2,kpsb2],trans_rot2)\n",
    "        self.img1=np.zeros((imgH,imgW,4),dtype=np.uint8)\n",
    "        self.img1[decalY3:decalY3+cardH,decalX3:decalX3+cardW,:]=img1\n",
    "\n",
    "        while True:\n",
    "            det_transform_3cards = transform_3cards.to_deterministic()\n",
    "            _img3,_lkps3,self.bbs3=augment(self.img3,self.lkps3,det_transform_3cards, False)\n",
    "            if _img3 is None: continue\n",
    "            _img2,_lkps2,self.bbs2=augment(self.img2,self.lkps2,det_transform_3cards, False)\n",
    "            if _img2 is None: continue\n",
    "            _img1,self.lkps1,self.bbs1=augment(self.img1,[cardKP,kpsa1,kpsb1],det_transform_3cards, False)\n",
    "            if _img1 is None: continue\n",
    "            break\n",
    "        self.img3=_img3\n",
    "        self.lkps3=_lkps3\n",
    "        self.img2=_img2\n",
    "        self.lkps2=_lkps2\n",
    "        self.img1=_img1\n",
    "        \n",
    "        self.class1=class1\n",
    "        self.class2=class2\n",
    "        self.class3=class3\n",
    "        self.listbba=[BBA(self.bbs1[0],class1),BBA(self.bbs2[0],class2),BBA(self.bbs3[0],class3),BBA(self.bbs3[1],class3)]\n",
    "        \n",
    "        # Construct final image of the scene by superimposing: bg, img1, img2 and img3\n",
    "        self.bg=scaleBg.augment_image(bg)\n",
    "        mask1=self.img1[:,:,3]\n",
    "        self.mask1=np.stack([mask1]*3,-1)\n",
    "        self.final=np.where(self.mask1,self.img1[:,:,0:3],self.bg)\n",
    "        mask2=self.img2[:,:,3]\n",
    "        self.mask2=np.stack([mask2]*3,-1)\n",
    "        self.final=np.where(self.mask2,self.img2[:,:,0:3],self.final)\n",
    "        mask3=self.img3[:,:,3]\n",
    "        self.mask3=np.stack([mask3]*3,-1)\n",
    "        self.final=np.where(self.mask3,self.img3[:,:,0:3],self.final)\n",
    "\n",
    "    def display(self):\n",
    "        fig,ax=plt.subplots(1,figsize=(8,8))\n",
    "        ax.imshow(self.final)\n",
    "        for bb in self.listbba:\n",
    "            rect=patches.Rectangle((bb.x1,bb.y1),bb.x2-bb.x1,bb.y2-bb.y1,linewidth=1,edgecolor='b',facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "    def res(self):\n",
    "        return self.final\n",
    "    def write_files(self,save_dir,display=False):\n",
    "        jpg_fn, xml_fn=give_me_filename(save_dir, [\"jpg\",\"xml\"])\n",
    "        plt.imsave(jpg_fn,self.final)\n",
    "        if display: print(\"New image saved in\",jpg_fn)\n",
    "        create_voc_xml(xml_fn,jpg_fn, self.listbba,display=display)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generation of a scene with 2 cards\n",
    "bg=backgrounds.get_random()\n",
    "img1,card_val1,hulla1,hullb1=cards.get_random()\n",
    "img2,card_val2,hulla2,hullb2=cards.get_random()\n",
    "\n",
    "newimg=Scene(bg,img1,card_val1,hulla1,hullb1,img2,card_val2,hulla2,hullb2)\n",
    "newimg.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generation of a scene with 3 cards\n",
    "bg=backgrounds.get_random()\n",
    "img1,card_val1,hulla1,hullb1=cards.get_random()\n",
    "img2,card_val2,hulla2,hullb2=cards.get_random()\n",
    "img3,card_val3,hulla3,hullb3=cards.get_random()\n",
    "\n",
    "newimg=Scene(bg,img1,card_val1,hulla1,hullb1,img2,card_val2,hulla2,hullb2,img3,card_val3,hulla3,hullb3)\n",
    "newimg.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the datasets\n",
    "Typically, you want to generate a training dataset and a validation dataset of different size and different destination directory.\n",
    "Modify the variable 'nb_cards_to_generate' and 'save_dir' accordingly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of the 2 cards scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cards_to_generate=100\n",
    "save_dir=\"data/scenes/val\"\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "for i in tqdm(range(nb_cards_to_generate)):\n",
    "    bg=backgrounds.get_random()\n",
    "    img1,card_val1,hulla1,hullb1=cards.get_random()\n",
    "    img2,card_val2,hulla2,hullb2=cards.get_random()\n",
    "    \n",
    "    newimg=Scene(bg,img1,card_val1,hulla1,hullb1,img2,card_val2,hulla2,hullb2)\n",
    "    newimg.write_files(save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of the 3 cards scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cards_to_generate=100\n",
    "save_dir=\"data/scenes/val\"\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "for i in tqdm(range(nb_cards_to_generate)):\n",
    "    bg=backgrounds.get_random()\n",
    "    img1,card_val1,hulla1,hullb1=cards.get_random()\n",
    "    img2,card_val2,hulla2,hullb2=cards.get_random()\n",
    "    img3,card_val3,hulla3,hullb3=cards.get_random()\n",
    "    \n",
    "    newimg=Scene(bg,img1,card_val1,hulla1,hullb1,img2,card_val2,hulla2,hullb2,img3,card_val3,hulla3,hullb3)\n",
    "    newimg.write_files(save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case you want to train YOLO with the generated datasets\n",
    "YOLO cannot directly exploit the Pascal VOC annotations files. You need to convert the xml files in txt files accordingly to the syntax explained here: https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects\n",
    "The script 'convert_voc_yolo.py' makes this conversion and also generates the txt file that contains all the images of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python convert_voc_yolo.py data/scenes/val data/cards.names data/val.txt\n",
    "#python convert_voc_yolo.py data/scenes/train data/cards.names data/train.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
